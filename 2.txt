ВВЕДЕНИЕ

Предметная область данного курсового проекта охватывает разработку программного продукта для автоматической суммаризации текстов в условиях обработки больших объёмов данных. Автоматическая суммаризация представляет собой процесс извлечения ключевой информации из исходного текста с целью создания краткого содержания.
Актуальность разработки обусловлена экспоненциальным ростом объемов текстовой информации в цифровую эпоху, что приводит к информационной перегрузке. Суммаризация позволяет быстро усваивать суть материалов, повышая эффективность работы в аналитике, научных исследованиях и документообороте.
Разработка программного продукта для распределённой суммаризации текстов актуальна из-за требований к скорости обработки и необходимости масштабируемости. Традиционные подходы не справляются с объёмами данных, измеряемыми гигабайтами и терабайтами. Распределённые системы, основанные на архитектуре Master-Slave, позволяют параллельно обрабатывать данные, минимизируя временные затраты и повышая отказоустойчивость.
Целью курсового проекта является разработка программного продукта на основе архитектуры Master-Slave для распределённой суммаризации текстов. Программный продукт должен обеспечивать эффективную и масштабируемую обработку текстовых данных.
Для достижения цели необходимо реализовать следующие задачи:
– разработка Master-узла с REST API для приёма данных от клиента и обеспечения единой точки входа в систему;
– реализация Master-Slave архитектуры с механизмом балансировки нагрузки (выбор наименее загруженного Slave-узла);
– обеспечение отказоустойчивости системы, включая возможность динамического добавления Slave-узлов и продолжение работы при выходе из строя отдельных узлов;
– разработка Slave-узла для обработки текста с применением алгоритма TextRank;
– организация эффективного внутреннего взаимодействия между Master- и Slave-узлами с использованием протокола UDP для минимизации задержек.
Таким образом, разработка представляет собой современное решение для эффективной обработки текстовых данных в распределенной среде, отвечающее требованиям производительности, масштабируемости и отказоустойчивости. 
1 АНАЛИЧЕСКИЙ ОБЗОР СРЕДСТВ РАЗРАБОТКИ

1.1 Постановка задачи и анализ предметной области

В современном информационном обществе наблюдается экспоненциальный рост объёмов текстовых данных, что создает проблему информационной перегрузки. Пользователям становится всё сложнее оперативно анализировать большие документы, научные статьи, техническую документацию и новостные потоки. Автоматическая суммаризация текстов (АСТ) представляет собой технологию обработки естественного языка, направленную на создание краткого, информативного содержания исходного документа с сохранением ключевых смыслов и фактов. Однако традиционные однопользовательские и однопоточные решения сталкиваются с фундаментальными ограничениями при обработке документов большого объёма (сотни тысяч и миллионы символов), где время обработки становится неприемлемым для интерактивной работы.
Формальная постановка задачи данного курсового проекта заключается в разработке программного продукта, реализующего распределённую систему для автоматической суммаризации текстов на основе архитектуры Master-Slave. Система должна функционировать по следующей схеме: клиентское приложение (веб-браузер) отправляет текстовый файл или текст на Master-узел через стандартизированный REST API. Master-узел, выступая в роли центрального координатора, анализирует состояние доступных вычислительных Slave-узлов и выбирает для обработки наименее загруженный из них. Выбранная задача передаётся на Slave-узел с использованием протокола UDP для минимизации сетевых задержек. Slave-узел выполняет алгоритм экстрактивной суммаризации TextRank и возвращает результат обратно на Master-узел, который, в свою очередь, отправляет итоговую сводку клиенту. Такая архитектура должна обеспечить возможность обработки текстов произвольной длины за счёт их разбиения на части (чанки) и распределения между несколькими Slave-узлами.
К разрабатываемой системе предъявляются следующие ключечные требования:
Система должна обеспечивать линейное или близкое к линейному уменьшение времени обработки при увеличении количества вычислительных узлов. Критически важна минимизация задержек на всех этапах: приём запроса, распределение нагрузки, передача данных и агрегация результатов.
Работа системы не должна полностью прекращаться при выходе из строя одного или нескольких Slave-узлов. Master-узел обязан осуществлять постоянный мониторинг состояния подчинённых узлов (например, через heartbeat-протокол) и оперативно исключать неисправные из пула доступных ресурсов, перенаправляя их задачи другим узлам.
Анализ существующих архитектурных подходов к построению распределённых вычислительных систем показывает, что для решаемой задачи оптимальным является выбор модели Master-Slave (Ведущий-Ведомый). Альтернативные подходы имеют существенные недостатки в данном контексте. Централизованная архитектура (единый мощный сервер) проста в реализации, но имеет принципиальный потолок производительности и создаёт единую точку отказа. Децентрализованные Peer-to-Peer (P2P) сети, хотя и обладают высокой отказоустойчивостью, чрезвычайно сложны в управлении, балансировке нагрузки и обеспечении согласованности состояния системы, что делает их избыточными для задачи с чётким разделением ролей. Архитектура Master-Slave обеспечивает золотую середину: Master-узел выполняет функции диспетчера и единой точки входа, что упрощает логику клиентов и управление кластером, в то время как пул идентичных Slave-узлов обеспечивает горизонтальное масштабирование вычислительной мощности. Данная модель идеально соответствует характеру задачи, где имеется чёткое разделение на управляющую логику (приём задачи, выбор исполнителя, сбор результатов) и вычислительную (независимое выполнение алгоритма TextRank над частью данных). Таким образом, выбор архитектуры Master-Slave предопределён требованиями к управляемости, масштабируемости и относительной простоты реализации распределённой системы для суммаризации текстов.

1.2 Задача автоматической суммаризации текстов

Автоматическая суммаризация текстов – это сложная и актуальная задача обработки естественного языка, ключевая цель которой заключается в создании краткого, но информативного содержания исходного документа с полным сохранением его смысловой нагрузки. В современных распределенных информационных системах АСТ является критически важным инструментом для борьбы с информационной перегрузкой и повышения эффективности анализа больших объемов текстовых данных.

1.2.1 При решении задачи АСТ традиционно выделяют два основных методологических подхода:
– экстрактивная суммаризация;
– абстракционная суммаризация.
Первый метод, выбранный для реализации в настоящей работе, базируется на извлечении наиболее значимых предложений непосредственно из оригинального текста и их последующем объединении в резюме. Главное преимущество экстрактивного подхода заключается в высокой степени достоверности и грамматической корректности результата, поскольку в нем используются только оригинальные фразы автора.
Второй подход основан на генерации совершенно нового текста, который может перефразировать или синтезировать основные идеи. Абстракция требует использования сложных генеративных нейросетевых моделей и не является подходящим выбором для распределенной архитектуры, сфокусированной на скорости и масштабируемости.

1.2.2 Учитывая ключевые требования к высокой скорости обработки и масштабируемости системы, в качестве основного алгоритма экстрактивной суммаризации выбран TextRank. TextRank представляет собой графовый алгоритм, который использует принцип PageRank для ранжирования предложений по их значимости. Предложения текста моделируются в виде узлов графа, а взвешенные ребра между ними определяют степень семантической схожести. 

1.2.3 Успешное развертывание задачи АСТ в Master-Slave архитектуре требует соблюдения ряда ключевых требований, которые определяют функциональные и нефункциональные свойства разработанной системы.
Во-первых, критическим свойством является масштабируемость. Система должна гарантировать эффективную обработку текстов произвольного объема, включая документы, достигающие сотен тысяч символов. Для работы с крупными текстами Master-узел автоматически переходит в режим распределенной обработки, инициируя разбиение текста на части (чанки) и их параллельное выполнение на нескольких Slave-узлах, что существенно сокращает общее время обработки.
Во-вторых, особое внимание уделяется производительности. Минимизация задержек достигается за счет нескольких оптимизаций: Master-узел реализует эффективную балансировку нагрузки при выборе наименее загруженных Slave-узлов. На уровне Slave-узлов достигается дополнительный прирост скорости за счет использования внутренней многопоточности при выполнении ресурсоемких итерационных расчетов алгоритма TextRank.
В-третьих, необходима высокая отказоустойчивость. Система должна быть устойчива к сетевым сбоям и внезапному падению вычислительных узлов. Master-узел реализует Heartbeat-протокол для постоянного мониторинга статуса Slave-узлов, что позволяет автоматически обнаруживать сбои и исключать неактивные узлы из распределения задач, обеспечивая непрерывность работы.
В-четвертых, для обеспечения корректной работы с данными требуется универсальность форматов. Система поддерживает различные типы файлов, что подразумевает обязательное включение этапа специфической предварительной обработки для каждого формата, гарантирующей извлечение чистого текстового контента и его очистку от метаданных перед суммаризацией.
Ключевым требованием для сохранения качества суммаризации является минимизация потери контекста при распределенной обработке. Поскольку независимое деление текста может нарушить смысловые связи, система применяет стратегию разбиения чанков с перекрытием, что позволяет Slave-узлам корректно построить граф семантических связей на границах разделенных частей.

1.3 Выбор языка программирования

Выбор языка программирования для разработки программного продукта определяется требованиями к производительности, простоте реализации, поддержке распределённых систем и интеграции с сетевыми протоколами. В данном разделе рассматриваются основные языки программирования: C#, Java, C++ и Python. Каждый язык анализируется по таким характеристикам, как парадигмы программирования, управление памятью, производительность, наличие библиотек и области применения. 

1.3.1 C# – объектно-ориентированный язык программирования от Microsoft, который с момента создания значительно усовершенствовался, получив функции для поддержки современных нагрузок. Его основная особенность – возможность определения типов и их поведения, что обеспечивает структурированный подход к коду. Ключевые характеристики включают автоматическую сборку мусора для освобождения памяти от недостижимых объектов, поддержку типов с возможностью значения null, а также лямбда-выражения для компактного описания функций.
C# реализует единую систему типов, где все типы наследуются от базового класса object, что обеспечивает единообразие операций. Язык поддерживает ссылочные и значимые типы, с возможностью динамической аллокации и хранения структур в стеке. Он также предлагает универсальные методы и итераторы для настройки поведения коллекций. Управление версиями в C# обеспечивает совместимость программ и библиотек со временем.
Программы на C# выполняются в среде .NET с использованием Common Language Runtime (CLR), поддерживающей различные языки и соответствующей стандарту Common Language Infrastructure (CLI). Код компилируется в межъязыковой код (Intermediate Language, IL), а при выполнении происходит JIT-компиляция в машинный код, включая автоматическую сборку мусора и управление ресурсами.
Ключевая особенность .NET – взаимодействие между языками через Common Type System (CTS). Код на C# может работать с кодами на других языках, таких как F# и Visual Basic. Одна сборка может содержать модули, написанные на разных языках, с прозрачными ссылками между типами. Платформа .NET предлагает обширные библиотеки для операций ввода-вывода, работы со строками, разбора XML, разработки веб-приложений и элементов управления, что активно используется в приложениях на C#.

1.3.2 Java – высокоуровневый язык программирования, разработанный компанией Sun Microsystems (ныне принадлежащей Oracle) в середине 1990-х годов. Он ориентирован на простоту, безопасность и переносимость, обеспечивая выполнение программ на любой платформе с установленной виртуальной машиной Java Virtual Machine (JVM). Java является объектно-ориентированным языком, использующим классы и объекты для организации кода. Автоматическое управление памятью снижает риск утечек памяти, упрощая создание надёжных и масштабируемых программ. Платформенная независимость достигается за счёт компиляции в байткод, выполняемый на JVM в операционных системах Windows, Mac OS X, Linux и других, что делает Java подходящей для кроссплатформенных приложений. 
Области применения Java включают настольные приложения, корпоративные веб-приложения, мобильные приложения для Android и серверные системы, благодаря высокой производительности, масштабируемости и безопасности. Встроенный сборщик мусора, аналогичный C#, использует алгоритм mark-and-sweep: достижимые объекты помечаются как "живые", а непомеченные блоки памяти освобождаются. JVM выполняет байткод из пакетов JDK (Java Development Kit), включающего инструменты разработки, или JRE (Java Runtime Environment), предназначенного только для выполнения программ. JDK содержит виртуальную машину, компилятор и другие инструменты, тогда как JRE обеспечивает согласованную среду выполнения, скрывая различия аппаратного обеспечения и операционных систем.

1.3.3 C++ – мощный язык программирования, широко применяемый в системном программировании, разработке игр и высокопроизводительных вычислениях. Он поддерживает объектно-ориентированное программирование, позволяя моделировать сущности реального мира через объекты, инкапсулирующие данные и поведение. Шаблоны в C++ обеспечивают обобщённое программирование, устраняя необходимость дублирования кода для разных типов данных. Управление памятью находится под полным контролем разработчика, что позволяет эффективно манипулировать ресурсами, но создаёт риски утечек памяти и ошибок. Указатели используются для прямого доступа к памяти и создания структур данных, однако их неправильное использование может привести к ошибкам нулевого указателя или утечкам памяти. 
C++ поддерживает множественное наследование, позволяя создавать сложные иерархии объектов, но это может вызывать проблемы, такие как двусмысленность. В отличие от C# и Java, в C++ отсутствует встроенный сборщик мусора. Существуют сторонние библиотеки, такие как Boehm-Demers-Weiser (BDW), использующая стандартный алгоритм сборки мусора (CGC), применяющая гибридный подход (подсчёт ссылок и сборка мусора) для повышения производительности. Однако эти библиотеки не заменяют полноценный сборщик мусора, и разработчикам необходимо тщательно управлять памятью, избегая висячих указателей и других ошибок.

1.3.4 Python – высокоуровневый язык программирования, разработанный Гвидо ван Россумом и выпущенный в 1991 году. Его популярность обусловлена простотой, читабельностью и универсальностью. Python поддерживает объектно-ориентированное, процедурное и функциональное программирование, что делает его подходящим для широкого спектра задач. Динамическая типизация делает Python медленнее статических языков, но оптимизация интерпретаторов повышает его производительность. Исторически Python использовался для написания скриптов, подготавливающих данные для программ на статических языках. Интуитивно понятный синтаксис позволяет быстро осваивать язык, сосредотачиваясь на решении задач, что делает его идеальным для начинающих программистов и образовательных учреждений.
Python применяется в веб-разработке, научных вычислениях, анализе данных, искусственном интеллекте и автоматизации. Обширная стандартная библиотека включает модули для работы с сетью, файлами, базами данных и текстом, ускоряя разработку. Кроссплатформенность (Windows, macOS, Linux) позволяет создавать универсальные приложения. Библиотеки для машинного обучения, такие как TensorFlow, Keras и PyTorch, делают Python популярным для разработки моделей искусственного интеллекта. Также он широко используется для автоматизации задач, таких как обработка данных и взаимодействие с API.

1.3.5 На основе проведённого сравнения для реализации программного продукта, предназначенного для распределённой суммаризации текстов, выбран язык C#, который обеспечивает оптимальный баланс между удобством разработки, встроенной поддержкой асинхронных операций и возможностями интеграции с платформой .NET для сетевых приложений. 
Для распределенной системы суммаризации текстов, где критически важны эффективное сетевое взаимодействие, параллельная обработка запросов и работа со строковыми данными, проводилось углубленное сравнение языков C# и C++ как наиболее релевантных кандидатов с принципиально разными подходами к разработке. 
Анализ выявил существенные различия в парадигмах управления памятью, которые напрямую влияют на надежность и скорость разработки. C# с его автоматической сборкой мусора исключает целый класс ошибок, связанных с утечками памяти и висячими указателями, что особенно ценно в системе с интенсивным сетевым обменом данными. C++ требует ручного управления памятью через new/delete, что хотя и дает максимальный контроль над ресурсами, но значительно увеличивает сложность отладки и сопровождения кода, создавая риски для стабильности конечного продукта.
Ключевым преимуществом C# является асинхронное программирование через async/await, что позволяет эффективно обрабатывать множество подключений без блокировки потоков, обеспечивая масштабируемость. В C++ для аналогичной функциональности нужны сторонние библиотеки, что увеличивает сложность разработки.
При рассмотрении инструментов для реализации сетевых компонентов C# демонстрирует явное превосходство благодаря интегрированной экосистеме. Наличие готового фреймворка ASP.NET Core для построения REST API и стандартных классов UdpClient/Socket для работы с протоколом UDP обеспечивает быструю и согласованную разработку всех компонентов системы. Разработка на C++ потребует интеграции различных сторонних библиотек для HTTP-взаимодействия и работы с сокетами, что создает дополнительные точки отказа и усложняет процесс сборки и развертывания.
С точки зрения производительности в контексте конкретной задачи – обработки текстовых данных и сетевой коммуникации – современные реализации .NET с поддержкой AOT-компиляции (NativeAOT) практически нивелируют традиционное преимущество C++ в скорости выполнения. При этом C# сохраняет безопасность типов и упрощает сопровождение кода.
Таким образом, несмотря на потенциально более высокую производительность C++ в чисто вычислительных задачах, для реализации распределенной системы суммаризации текстов выбор останавливается на C# и платформе .NET. Это решение обусловлено оптимальным сочетанием производительности, богатой стандартной библиотеки, развитых средств для асинхронного сетевого программирования и значительно более низких затрат на разработку и сопровождение, что является определяющим фактором для успешной реализации проектируемого программного продукта.

1.4 Обзор сетевых протоколов

Сетевые протоколы играют ключевую роль в передаче данных в распределённых системах. В этом разделе рассматриваются TCP/IP и UDP, используемые для взаимодействия между клиентом, master-узлом и slave-узлами. Анализ включает их архитектуру, функциональные возможности, преимущества и недостатки, с акцентом на применимость к распределённой обработке текстов. Выбор UDP для внутренней коммуникации оправдан высокой скоростью и низкими накладными расходами, тогда как TCP/IP используется в REST API для надёжного взаимодействия клиента с master-узлом.

1.4.1 TCP/IP представляет собой многослойный стек, обеспечивающий передачу данных в сетях, от локальных до глобальных, например, в Интернете. Его модульная структура включает несколько уровней, выполняющих определённые функции, что делает его гибким и масштабируемым. Основные задачи TCP/IP связаны с адресацией и конфигурированием интерфейсов.
Канальный уровень отвечает за физическую передачу данных через технологии, такие как Ethernet или Wi-Fi. Сетевой уровень реализуется протоколом IP, который управляет маршрутизацией и делит данные на пакеты. Существуют две версии: IPv4 (32 бита) и IPv6 (128 бит).
Транспортный уровень представлен протоколом TCP, который обеспечивает надёжную передачу данных с контролем целостности и порядком. Это достигается через трёхстороннее рукопожатие и механизм подтверждений. Однако, данные механизмы увеличивают накладные расходы, что делает TCP менее подходящим для задач с минимальной задержкой.
На рисунке 1.1 представлена схема передачи данных с использованием протокола TCP.

 

Рисунок 1.1 – Схема передачи данных с протоколом TCP

1.4.2 Протокол UDP (User Datagram Protocol) предназначен для связи без установки соединения. Отправитель передаёт пакеты другому узлу без предварительного согласования, не проверяя готовность получателя и не ожидая подтверждений доставки. Это обеспечивает высокую скорость передачи, делая UDP подходящим для задач, где минимизация задержки важнее надёжности. UDP не требует установления соединения, что снижает затраты на коммуникацию. Протокол не гарантирует доставку пакетов, их порядок или целостность, что является его основным недостатком, но одновременно преимуществом, так как минимизирует накладные расходы. Заголовок UDP имеет фиксированный размер 8 байт (против 20–40 байт у TCP), включая порт отправителя, порт получателя, длину заголовка и данных, а также контрольную сумму для проверки целостности. Максимальный размер пакета составляет 65 535 байт, но на практике он ограничен.
UDP идеально подходит для приложений, где скорость важнее надёжности, например, для внутренней передачи данных между master и slave-узлами в распределённых системах, где потери пакетов редки благодаря контролируемой сетевой среде. В контексте данного курсового проекта UDP используется для передачи текстов от master-узла к slave-узлу для выполнения суммаризации.
На рисунке 1.2 представлена схема передачи данных с использованием протокола UDP.

 

Рисунок 1.2 – Схема передачи данных с протоколом UDP

1.4.3 TCP/IP обеспечивает надёжную передачу данных благодаря подтверждениям, восстановлению порядка и управлению потоком, но это увеличивает задержки и накладные расходы из-за сложного заголовка и дополнительных механизмов контроля. UDP превосходит TCP по скорости за счёт отсутствия соединения и минимального заголовка, но не гарантирует доставку или порядок пакетов, что приемлемо в сценариях с низкой вероятностью потерь. 

1.5 Обоснование выбора архитектуры и подхода к масштабированию

1.5.1 При проектировании распределенной системы суммаризации, способной обрабатывать большие объемы данных, ключевым этапом является выбор оптимальной архитектурной модели, которая обеспечит заданный уровень масштабируемости и управляемости. Были рассмотрены и оценены такие распространенные модели, как клиент-серверная и микросервисная архитектуры.
Клиент-серверная модель, несмотря на простоту управления, создаёт критическое узкое место в производительности, поскольку вся вычислительная нагрузка ложится на единый серверный узел. Микросервисная архитектура предлагает высокую гибкость, но её реализация является избыточной и значительно усложняет разработку для специализированной задачи, не требующей такого уровня декомпозиции.
Архитектура Master-Slave позволяет эффективно разделить управляющую логику (Master-узел) и вычислительную логику (Slave-узлы). Master-узел выполняет функции централизованного управления заданиями, что упрощает балансировку нагрузки, в то время как пул Slave-узлов обеспечивает горизонтальное масштабирование. Использование Master-Slave позволяет избежать проблем с единой точкой отказа и потолком производительности (как в клиент-серверной модели) и одновременно преодолеть сложности, связанные с управлением, балансировкой и агрегацией результатов в децентрализованных P2P-сетях. Таким образом, Master-Slave оптимально соответствует характеру задачи автоматической суммаризации текстов (АСТ), обеспечивая баланс между управляемостью, масштабируемостью и относительной простотой реализации.

1.5.2 Для достижения максимальной производительности и полного использования ресурсов кластера в рамках архитектуры Master-Slave применяется комбинированный подход к масштабированию, включающий два взаимодополняющих уровня:
– горизонтальное масштабирование (распределённая обработка);
– вертикальное масштабирование (многопоточная обработка).
На первом уровне Master-узел реализует стратегию распределённой обработки данных. Крупные тексты автоматически разбиваются на независимые части и распределяются между несколькими Slave-узлами для одновременного выполнения алгоритма. Горизонтальное масштабирование обеспечивает основное увеличение производительности системы пропорционально количеству подключённых Slave-узлов, что позволяет эффективно обрабатывать объёмные документы.
На втором уровне для дополнительной оптимизации вычислительных операций каждый Slave-узел использует многопоточные вычисления. Вертикальное масштабирование применяется для ускорения наиболее ресурсоёмких этапов алгоритма: параллельная предобработка текста, распределённое вычисление матрицы схожести между предложениями и оптимизация итерационного процесса пересчёта весов. Реализация основана на средствах платформы .NET, таких как класс Parallel и механизмы пулов потоков, и обеспечивает дополнительный прирост производительности каждого отдельного узла без увеличения их количества.
Такая двухуровневая стратегия масштабирования позволяет системе адаптивно распределять вычислительную нагрузку в зависимости от объёма обрабатываемых данных, обеспечивая высокую производительность как для малых, так и для больших текстов.

1.6 Перечень используемых технологий

Для реализации программного продукта, предназначенного для распределённой суммаризации текстов на основе master-slave архитектуры, выбраны следующие технологии и инструменты, обеспечивающие эффективную разработку и выполнение задач:
Язык программирования: C# (.NET) выбран за оптимальное сочетание производительности, поддержки асинхронного программирования (async/await) и встроенных инструментов платформы .NET для работы с сетевыми протоколами и обработки текстов. Фреймворк ASP.NET Core используется для реализации REST API, а классы System.Net.Sockets – для работы с UDP.
REST API (на базе TCP/IP) обеспечивает надёжное взаимодействие между клиентом и master-узлом, гарантируя доставку текстовых данных. 
UDP используется для внутренней передачи данных от master-узла к slave-узлам, минимизируя задержки благодаря отсутствию установления соединения и минимальному размеру заголовка.
Алгоритм TextRank применяется на slave-узлах для автоматической суммаризации текстов. Алгоритм основан на графовой модели, где предложения представлены вершинами, а их связи – рёбрами, определяемыми косинусным сходством. Реализация использует библиотеки, совместимые с C#, такие как возможные порты NetworkX или собственные графовые структуры.
Библиотеки и инструменты .NET:
– ASP.NET Core необходим для реализации REST API, обеспечивающего стандартизированный интерфейс для приёма текстов от клиента.
– System.Net.Sockets нужен для организации высокоскоростной передачи данных по UDP между master- и slave-узлами.
– библиотеки обработки текстов для предварительной обработки текстов перед применением TextRank.
Выбор технологий обусловлен их совместимостью, производительностью и способностью поддерживать масштабируемую распределённую обработку текстовых данных в соответствии с задачей проекта. 
2 АЛГОРИТМИЧЕСКИЙ РАЗБОР ЗАДАЧИ

2.1 Архитектура приложения

Разработанное приложение построено по клиент-серверной модели с явным разделением на front-end и back-end, дополненной внутренней master-slave архитектурой распределённых вычислений.
Front-end реализован как одностраничное веб-приложение, доступное через любой современный браузер. Пользовательский интерфейс позволяет загружать файлы различных форматов (TXT, PDF, DOC/DOCX, RTF, ODT), задавать желаемый коэффициент сжатия (ratio), запускать процесс суммаризации и получать готовый результат в удобочитаемом виде вместе со статистикой обработки. Передача данных между клиентом и сервером осуществляется исключительно через стандартизированный REST API по протоколу HTTP/HTTPS с поддержкой multipart/form-data для загрузки файлов и JSON для текстовых запросов.
Back-end состоит из двух логических уровней: master и slave.
Master-узел – центральный координатор и единственная точка входа для всех внешних клиентов. Он выполняет следующие функции:
– приём и валидацию входящих HTTP-запросов;
– определение формата загруженного файла и извлечение чистого текста;
– хранение оригинальных файлов в локальной директории uploads;
– мониторинг состояния всех зарегистрированных slave-узлов;
– выбор исполнителя по принципу минимальной текущей нагрузки;
– распределение задач (простых и чанкированных);
– сбор и агрегацию частичных результатов;
– возврат итогового summary клиенту в формате JSON;
– fallback-обработку на самом master-узле при отсутствии доступных slave-узлов.
Slave-узлы – вычислительные рабочие узлы, количество которых может динамически увеличиваться или уменьшаться без остановки системы. Каждый slave:
– автоматически регистрируется на master-узле по UDP при запуске;
– периодически отправляет heartbeat-сообщения для подтверждения активности;
– принимает задачи по UDP (как одиночные, так и в виде последовательности чанков);
– выполняет непосредственно алгоритм TextRank над полученным текстом;
– возвращает результат и уведомление о завершении обратно на master.
Внутреннее взаимодействие между master и slave-узлами организовано исключительно по протоколу UDP на фиксированных портах (6000 – регистрация и heartbeat, 6001 – результаты задач). Такой выбор обусловлен минимальными накладными расходами и высокой скоростью передачи в локальной или контролируемой сети.
Для текстов небольшого и среднего объёма применяется простая передача всей задачи одному выбранному slave-узлу. При обработке объёмных документов автоматически включается режим распределённой обработки: текст разбивается на чанки фиксированного размера, каждый чанк отправляется на отдельный наименее загруженный slave, после чего master собирает и объединяет частичные summary в правильном порядке.
Система обладает высокой отказоустойчивостью:
– при временной недоступности отдельных slave-узлов задачи автоматически перенаправляются на другие;
– при полном отсутствии рабочих узлов master переходит в режим локальной обработки;
– предусмотрен механизм очистки неактивных узлов и таймаутов для «зависших» задач.
По своему назначению и характеру взаимодействия приложение относится к категории онлайн-редакторов текстов с синхронным типом связи: клиент отправляет запрос и блокируется до получения окончательного результата в рамках одного HTTP-соединения.
На рисунке 2.1 представлена общая архитектура разрабатываемого приложения. 

 

Рисунок 2.1 – Архитектура приложения

Архитектура приложения для распределенной суммаризации текстов разработана таким образом, чтобы обеспечить оптимальное взаимодействие между клиентами и сервером, а также добиться высокой производительности и минимальных задержек при выполнении операций над текстами. Эта архитектура включает несколько ключевых компонентов, которые совместно обеспечивают её функциональность.
Рассмотрим основные компоненты этой архитектуры и этапы работы приложения, которое включает обработку текста по запросу клиента.

2.2	Цикл работы распределенного приложения

Цикл работы распределенного приложения – это последовательность шагов, через которые проходят компоненты приложения для выполнения запросов пользователя и обеспечения обмена данными между узлами системы. На рисунке 2.2 изображен цикл работы.

 

Рисунок 2.2 – Упрощенный цикл работы приложения

Этот цикл можно разбить на несколько основных этапов:
– отправка запроса клиентом;
– обработка файла на master-узле;
– выбор slave-узла для обработки;
– передача задачи на slave-узел;
– обработка текста на slave-узле;
– возврат результата на master-узел;
– передача ответа клиенту;
– отображение данных пользователю.
Пользователь инициирует действие, например, отправку текстового файла для суммаризации, с помощью интерфейса приложения. Клиентское приложение формирует запрос к системе, включающий:
– файл для обработки;
– коэффициент сжатия;
– метаданные файла.
После формирования запроса клиентское приложение передает его по сети к распределенной системе через REST API на master-узел. Запрос проходит через стандартные HTTP-методы, обеспечивая надежную передачу данных между клиентом и сервером.
Master-узел принимает запрос и начинает обработку файла. На этом этапе происходит определение формата файла и его преобразование в текстовый вид. Система поддерживает различные форматы файлов. Для каждого формата применяется соответствующий алгоритм извлечения текста.
После успешного преобразования файла в текст master-узел анализирует доступные slave-узлы и выбирает наименее загруженный для обработки задачи. Алгоритм выбора основан на принципе минимальной нагрузки – учитывается количество текущих задач на каждом slave-узле. Это обеспечивает равномерное распределение нагрузки и предотвращает перегрузку отдельных узлов системы.
При сложных операциях, когда текст превышает определенный размер, master-узел может разделить запрос на несколько параллельных задач для более быстрой обработки. Текст разбивается на логические части по предложениям, и каждая часть отправляется на отдельный slave-узел. Это позволяет значительно ускорить обработку объемных документов.
Передача задачи на slave-узел осуществляется с использованием протокола UDP, который был выбран для минимизации задержек при передаче данных между узлами. Для небольших текстов используется стандартная передача, для больших – чанкованная передача, когда текст разбивается на части и отправляется последовательно с подтверждением получения.
На slave-узле происходит обработка текста с применением алгоритма TextRank. Этот процесс включает несколько этапов: предобработку текста, разделение на предложения, построение графа предложений, вычисление весов предложений и выбор наиболее значимых предложений для итоговой суммаризации. Алгоритм учитывает семантические связи между предложениями, что позволяет сохранить основную смысловую нагрузку исходного текста.
После завершения обработки slave-узел отправляет результат обратно на master-узел через UDP-протокол. Результат включает суммаризированный текст, информацию об успешности выполнения задачи и метаданные обработки. Slave-узел также отправляет уведомление о завершении задачи, что позволяет master-узлу обновить информацию о текущей нагрузке на данный узел.
Если данные распределены между несколькими узлами (при обработке больших текстов), master-узел синхронизирует результаты обработки для поддержания согласованности. Частичные результаты, полученные от разных slave-узлов, объединяются в единый ответ. При этом сохраняется логическая структура исходного текста – предложения располагаются в том же порядке, в котором они встречались в оригинале.
Когда узлы завершили свои части задачи, необходимо собрать все результаты для передачи клиенту. Если данные запрашивались с нескольких узлов, агрегируются частичные результаты. Данные, полученные от нескольких источников, объединяются в единый ответ. Если часть узлов не смогла выполнить операцию, система может предпринять меры для восстановления данных или уведомить клиента о частичной неудаче.
После обработки запроса сервер формирует ответ для клиента:
– форматирование данных в JSON-формат;
– код состояния операции;
– отправка ответа через REST API.
Ответ включает суммаризированный текст, статистику обработки (количество символов в исходном и обработанном тексте, коэффициент сжатия), имя файла и идентификатор задачи. Это позволяет клиенту получить полную информацию о результате обработки.
На клиенте данные, полученные от сервера, обрабатываются и отображаются пользователю. Веб-интерфейс обеспечивает удобное представление результатов – суммаризированный текст отображается в отдельной области, а статистика обработки показывается в виде наглядных цифр. Пользователь имеет возможность скопировать результат или выполнить дополнительные действия с обработанным текстом.
Система также обеспечивает обработку ошибок на всех этапах цикла работы. В случае недоступности slave-узлов master-узел может использовать резервный алгоритм суммаризации или уведомить пользователя о временной невозможности обработки. Механизм повторных попыток и таймаутов обеспечивает надежность работы системы даже в условиях временных сбоев сети или перегрузки узлов.

2.3 Алгоритм суммаризации TextRank

Алгоритм суммаризации текстов путем применения TextRank является эффективным методом, который позволяет извлекать ключевые предложения из исходного текста, сохраняя при этом основные идеи и смысловую нагрузку. Основная идея TextRank – это представление текста в виде графа и вычисление значимости предложений на основе их связей с другими предложениями. Этапы суммаризации TextRank:
– предобработка текста;
– разделение текста на предложения;
– построение графа предложений;
– вычисление весов предложений;
– выбор ключевых предложений;
– формирование итоговой суммаризации.
На рисунке 2.3 представлена блок-схема алгоритма.

 

Рисунок 2.3 – Алгоритм TextRank

Предобработка текста включает очистку от лишних пробелов, переносов строк и специальных символов. Текст нормализуется для последующей обработки. Также выполняется приведение к единому регистру и удаление лишних символов. На этом этапе текст подготавливается для дальнейшего анализа, устраняются возможные помехи и нестандартные форматирования.
Разделение текста на предложения происходит по точкам, восклицательным и вопросительным знакам. Каждое предложение обрабатывается отдельно. Это облегчает работу алгоритма, так как мелкие синтаксические конструкции можно анализировать независимо. Разделение выполняется с учетом особенностей языка и пунктуации.
Построение графа предложений представляет каждый отдельный предложение как вершину графа. Ребра между вершинами устанавливаются на основе семантической близости предложений, вычисляемой через косинусное сходство их векторных представлений. Каждое предложение преобразуется в набор значимых слов, исключая стоп-слова и короткие слова.
Данный метод позволяет отделить более значимые предложения (с большим количеством связей) от менее значимых, которые содержат второстепенную информацию или детали. Итерационный процесс вычисления весов продолжается до достижения сходимости или выполнения заданного количества итераций.
Выбор ключевых предложений происходит на основе вычисленных весов. Предложения ранжируются по убыванию значимости, и выбирается заданное количество наиболее важных предложений в соответствии с коэффициентом сжатия.
Формирование итоговой суммаризации выполняется путем объединения выбранных предложений в том порядке, в котором они встречались в исходном тексте. Это позволяет сохранить логическую структуру и последовательность изложения. Алгоритм обеспечивает, чтобы результирующий текст был связным и понятным.

2.4 Алгоритм распределения нагрузки на узлы

Для эффективного распределения вычислительной нагрузки в распределенной системе суммаризации текстов реализован алгоритм Least Load (наименьшая нагрузка). Данный алгоритм оптимально подходит для задач с переменной вычислительной сложностью, где время обработки каждого текста может существенно отличаться.
На рисунке 2.4 представлена схема алгоритма.
 

Рисунок 2.4 – Алгоритм распределения нагрузки на узлы

При поступлении новой задачи на суммаризацию master-узел выполняет анализ текущей загрузки всех доступных slave-узлов. Для каждого узла вычисляется метрика нагрузки как количество активных задач.
Узел с минимальным значением метрики выбирается для обработки новой задачи. При равенстве нагрузки между несколькими узлами применяется случайный выбор из наименее загруженных узлов.
Ключевые преимущества алгоритма:
– минимизация времени ожидания – задачи направляются на узлы с наименьшей очередью;
– автоматическая балансировка – система адаптируется к различной вычислительной сложности задач;
– простота реализации – низкие накладные расходы на принятие решений
– масштабируемость – легко добавлять новые узлы без изменения логики распределения.
В текущей реализации master-узел поддерживает таблицу состояния slave-узлов, где для каждого узла хранится счетчик активных задач. При регистрации нового slave-узла его счетчик инициализируется нулевым значением. При распределении задачи счетчик увеличивается, а после завершения обработки - уменьшается.
Для больших текстов система автоматически переходит в режим распределенной обработки, где текст разбивается на части и распределяется между несколькими наименее загруженными узлами. Это позволяет ускорить обработку объемных документов и эффективно использовать ресурсы кластера.
Алгоритм доказал свою эффективность в условиях реальной эксплуатации, обеспечивая равномерную загрузку узлов при варьирующейся сложности текстов и количестве одновременных запросов. 
3	РАСПРЕДЕЛЕННОЕ ПРИЛОЖЕНИЕ «СУММАРИЗАЦИЯ 
ТЕКСТА»

3.1	Состав и взаимодействие компонентов системы

Master-узел является центральным компонентом распределённой системы обработки текста, координирующим работу всей системы. Он выполняет несколько ключевых функций: приём запросов от клиентов через HTTP-интерфейс, управление slave-узлами, распределение задач по созданию текстовых сводок и сбор результатов. Архитектура master-узла построена на взаимодействии пяти основных классов, каждый из которых отвечает за определённый аспект работы системы.
MasterNode – главный класс, который инициализирует и запускает всю систему. Он настраивает HTTP-сервер для взаимодействия с клиентами и UDP-слушатели для связи с slave-узлами. Класс отвечает за фоновые процессы, такие как периодическая очистка неактивных узлов, и обеспечивает корректное завершение работы системы.
HttpRequestHandler – обработчик HTTP-запросов, который обеспечивает интерфейс взаимодействия с клиентами. Он поддерживает несколько типов запросов: загрузку файлов через форму, JSON-запросы на создание сводки, запросы статуса системы и обслуживание статических файлов веб-интерфейса. Класс анализирует входящие запросы, извлекает текстовые данные и передаёт их на дальнейшую обработку.
TaskDistributor – ядро системы распределения задач, принимающее решение о стратегии обработки текста. В зависимости от размера текста и доступности вычислительных ресурсов, класс выбирает оптимальный способ обработки: стандартную отправку на один slave-узел, чанкованную передачу для средних текстов или распределённую обработку для больших объёмов данных. Класс также управляет сбором и объединением результатов от различных узлов.
SlaveNodeManager – менеджер slave-узлов, поддерживающий актуальное состояние всех доступных вычислительных ресурсов. Он отслеживает регистрацию новых узлов, обновляет информацию об их активности через heartbeat-сообщения, распределяет нагрузку равномерно между узлами и автоматически удаляет неактивные ресурсы. Класс обеспечивает балансировку нагрузки и отказоустойчивость системы.
NetworkCommunicator – сетевой коммуникатор, реализующий взаимодействие с slave-узлами через UDP-протокол. Он обеспечивает двустороннюю связь: отправку задач на обработку и приём результатов. Класс поддерживает различные режимы передачи данных в зависимости от размера текста, гарантирует доставку чанкованных данных и управляет таймаутами при ожидании ответов.
Взаимодействие этих классов образует гибкую и масштабируемую архитектуру, способную адаптироваться к изменяющейся нагрузке и количеству доступных вычислительных ресурсов. Такая организация позволяет эффективно обрабатывать тексты различного объёма, обеспечивая высокую производительность и надёжность системы в целом.
Slave-узлы являются вычислительными единицами распределённой системы, непосредственно выполняющими задачи по созданию текстовых сводок. Каждый slave-узел работает автономно, регистрируется в master-узле и ожидает задания на обработку. Архитектура slave-узлов построена вокруг трёх основных классов, которые обеспечивают сетевое взаимодействие, управление задачами и выполнение алгоритмов суммирования.
SlaveNode – основной класс, представляющий отдельный вычислительный узел. Он отвечает за регистрацию в системе, поддержание связи с master-узлом через heartbeat-сообщения, приём и обработку задач различного типа. Класс реализует несколько режимов работы: обработка стандартных задач, сборка чанкованных текстов и выполнение частей распределённых задач. Slave-узел автоматически находит свободный UDP-порт для работы, что позволяет запускать несколько экземпляров на одном физическом сервере. Реализация включает механизмы отказоустойчивости, такие как таймауты ожидания чанков и очистка зависших задач.
TextSummarizer – алгоритмический движок, который реализует логику создания текстовых сводок на основе алгоритма TextRank. Этот же класс используется в master-узле в качестве резервного обработчика, что обеспечивает единообразие результатов. Алгоритм выполняет графовый анализ текста, выделяя наиболее значимые предложения через анализ их взаимосвязей. Реализация оптимизирована для работы с русским языком и включает предобработку текста, удаление стоп-слов и эффективные структуры данных для работы с большими объёмами текста.
ChunkedTaskState – внутренний класс управления состоянием для задач, передаваемых по частям. Он отслеживает получение всех чанков текста, контролирует их корректную сборку в исходный текст и управляет таймаутами ожидания недостающих частей. Класс обеспечивает надёжность при работе в условиях возможных потерь сетевых пакетов и асинхронной доставки данных.
Сетевое взаимодействие slave-узлов реализуется через UDP-протокол, что обеспечивает низкие накладные расходы и возможность работы в условиях нестабильных сетевых соединений. Slave-узел поддерживает три основных типа сообщений:
– регистрационные сообщения для подключения к master-узлу;
– heartbeat-сообщения для подтверждения активности;
– результаты выполнения задач.
Управление задачами в slave-узле включает несколько режимов обработки:
– стандартный режим для текстов до 10000 символов;
– чанкованный режим для текстов среднего размера;
– распределённый режим, где slave обрабатывает только часть большого текста.
Мониторинг и диагностика реализованы через подробное логирование всех этапов работы, что позволяет отслеживать производительность каждого узла и диагностировать возможные проблемы. Slave-узлы автоматически освобождают ресурсы после завершения задач и корректно завершают работу при получении команды остановки.
Архитектура slave-узлов обеспечивает горизонтальную масштабируемость системы: добавление новых узлов увеличивает общую производительность системы пропорционально их количеству. Каждый slave-узел является независимым и может быть развёрнут на отдельном физическом или виртуальном сервере, что позволяет распределять нагрузку и повышать отказоустойчивость системы в целом.

3.2	Определение эффективности работы при низкой нагрузке

Целью данного раздела является сравнительный анализ производительности системы при использовании локальной (централизованной) и распределённой (многопоточной) обработки текстов. Тестирование проводилось на текстах различного объёма: от 5 000 до 200 000 символов. Для каждого объёма выполнялось по 4 прогона, результаты усреднялись и фиксировались в таблице.
Первые два теста (5 000 и 20 000 символов) показали, что однопоточная обработка оказывается быстрее распределённой. Этот, на первый взгляд, парадоксальный результат объясняется значительными накладными расходами, возникающими при организации распределённой обработки. Для малых объёмов данных время, затрачиваемое на разделение текста на чанки, передачу данных по сети, синхронизацию результатов и сборку финальной сводки, превышает выгоду от параллельного выполнения вычислений.
Ситуация кардинально меняется для текстов объёмом от 50 000 символов. Здесь распределённая обработка демонстрирует существенное преимущество: время выполнения сокращается с 11,778 секунд до 3,169 секунд. Для максимального объёма в 200 000 символов однопоточный режим не справляется в разумные сроки (превышает таймаут в 100 секунд), в то время как распределённая система успешно обрабатывает текст за 20,008 секунд.
Как видно из таблицы 3.1, распределённая обработка медленнее централизованной на малых задачах. Это является закономерным следствием малой нагрузки: процессор больше тратит времени на организацию потоков и сетевую коммуникацию, чем на непосредственное выполнение задачи. На более крупных текстах распределённая обработка становится лидером, что свидетельствует о её эффективности при работе с большими объёмами данных.

Таблица 3.1 – Время суммаризации для малых и больших текстов
Размер текста 
(символов)	Централизованная 
обработка	Распределенная 
обработка
5000	0.153	0.413
20000	2.435	3.323
50000	11.78	3.169
200000	100	20.008

3.2.1 Для анализа эффективности работы программы были проведены вычисления. Для количественной оценки эффективности распределённой обработки используются метрики ускорения и эффективности.
Ускорение вычисляется по формуле:

"S" _"n"  "="  "T" _"1" /"T" _"n"   "                                                            (3.1)" 

где T₁ – время однопоточной обработки, Tₙ – время многопоточной обработки при использовании n узлов.
Результаты расчета:
– для 5 000 символов: S₄ = 0,153 / 0,413 = 0,37;
– для 20 000 символов: S₄ = 2,435 / 3,323 = 0,73;
– для 50 000 символов: S₄ = 11,778 / 3,169 = 3,72;
– для 200 000 символов: S₄ > 100 / 20,008 > 5,0.
Значения ускорения меньше единицы для малых текстов подтверждают неэффективность распределенной обработки в этом диапазоне. Ускорение 3,72 и более 5,0 для больших текстов свидетельствует о высокой эффективности распределенной обработки.
Эффективность показывает, насколько оптимально используются вычислительные ресурсы:

E_n=S_n/n                                                             (3.2)

где n – количество используемых узлов (в нашем случае n = 4).
Результаты расчета:
– для 5 000 символов: E₄ = 0,37 / 4 = 0,0925 (9,25%);
– для 20 000 символов: E₄ = 0,73 / 4 = 0,1825 (18,25%);
– для 50 000 символов: E₄ = 3,72 / 4 = 0,93 (93%);
– для 200 000 символов: E₄ > 5,0 / 4 > 1,25 (>125%).
Низкая эффективность для малых текстов (9-18%) объясняется тем, что процессоры большую часть времени простаивают, ожидая завершения сетевых операций и синхронизации. Высокая эффективность для больших текстов (93-125%) указывает на почти идеальное использование вычислительных ресурсов, при котором узлы большую часть времени заняты полезными вычислениями.
3.2.2 Закон Амдала описывает теоретический предел ускорения параллельной программы:

S_n^'=1/((1-a)+a/n)                                                     (3.3)

где a – доля последовательного кода, не поддающегося распараллеливанию, (1 - a) – доля параллельного кода, n – количество процессоров.
Используя экспериментальные данные, можно определить долю последовательного кода для разных объемов текста:
Для 5 000 символов при S₄ = 0,37 и n = 4:

S^4=1/((1-a)+a/4)=0,37                                          (3.4)

Решая уравнение, получаем a ≈ 0,87 (87%)
Для 50 000 символов при S₄ = 3,72 и n = 4:

S^4=1/((1-a)+a/4)                                                   (3.5)

Решая уравнение, получаем a ≈ 0,07 (7%)
Этот результат имеет важное практическое значение: для малых текстов 87% операций являются последовательными (в основном – накладные расходы на организацию распределения), тогда как для больших текстов доля последовательных операций снижается до 7%, что делает распределенную обработку чрезвычайно эффективной.

3.2.3 Закон Густафсона-Барсиса предлагает альтернативный подход к оценке масштабируемости:

S_n^''=n+(1-n)⋅a                                             (3.6)

где a — доля последовательных операций, n – количество процессоров.
Подставляя экспериментально определенные значения a:
– для 5 000 символов (a = 0,87): S₄'' = 4 + (1 - 4) × 0,87 = 1,39
– для 50 000 символов (a = 0,07): S₄'' = 4 + (1 - 4) × 0,07 = 3,79
Сравнение с экспериментальными значениями показывает, что закон Густафсона-Барсиса более оптимистичен для малых текстов, но хорошо предсказывает поведение системы для больших объёмов данных.

3.3 Результаты нагрузочного тестирования

Для оценки производительности и стабильности разработанной системы было проведено комплексное нагрузочное тестирование, включающее четыре различных сценария: базовую нагрузку, постепенное увеличение нагрузки, стресс-тест и длительную проверку стабильности. Для верификации эффективности архитектуры Master-Slave тестирование проводилось в двух ключевых конфигурациях: в Базовом режиме (Master-узел работает автономно, имитируя однопоточное решение) и в Распределенном режиме (Master-узел управляет кластером из шести Slave-узлов). Тестирование проводилось на локальной машине с процессором AMD Ryzen 7 4800H и 16 ГБ оперативной памяти.
Базовый тест с 10 виртуальными пользователями, каждый из которых выполнял 5 последовательных запросов на суммаризацию текстов различного объёма, показал высокую надёжность системы в обеих конфигурациях. Из 50 выполненных запросов 49 завершились успешно, что соответствует уровню доступности 98,0%. Среднее время отклика в автономном режиме составило 8299,5 мс, при этом наблюдался значительный разброс значений – от минимальных 9 мс до максимальных 37452 мс. Пропускная способность в автономном режиме достигла 1,08 запросов в секунду (RPS), а в распределенном режиме она оказалась несколько ниже – 1,02 RPS. Это объясняется неизбежными сетевыми накладными расходами на сериализацию, передачу задачи по UDP и мониторинг узлов Heartbeat, которые при малой вычислительной нагрузке временно превышают выгоду от распараллеливания.
Тест с постепенным увеличением нагрузки также продемонстрировал схожую картину при низком уровне конкуренции. В автономном режиме система сохраняла стабильную производительность с 50% запросов быстрее 65 мс и средней пропускной способностью 10,51 RPS. В распределенном режиме при низких нагрузках наблюдалось падение успешности, что указывало на достижение системой точки насыщения, связанной с недостаточной пропускной способностью Master-узла по обработке входящих/исходящих UDP-пакетов, однако это проблема была решена оптимизацией.
Основным доказательством эффективности архитектуры послужил Стресс-тест, длившийся 120 секунд при нагрузке, плавно увеличивающейся до 50 одновременных пользователей. В автономном режиме система достигла точки насыщения при 32 пользователях, после чего среднее время отклика возрастало до 4592 мс, стабилизируясь на уровне 1682 мс (50-й перцентиль), при этом максимальная пропускная способность составила 9,91 RPS. Однако, при активации 6 Slave-узлов система продемонстрировала значительный скачок производительности. В распределенном режиме пропускная способность увеличилась до 15,25 RPS, что представляет собой прирост на 53,9%. Более того, медианное время отклика (50-й перцентиль) сократилось с 1682 мс до 489 мс, что означает ускорение обработки запросов более чем в 3,4 раза. Эти результаты однозначно подтверждают, что Master-узел успешно распределяет вычислительный объем, а архитектура Master-Slave обеспечивает эффективное горизонтальное масштабирование.
Для наглядной демонстрации масштабируемости системы был построен график зависимости среднего времени отклика от количества одновременных пользователей (рис. 3.1). График отражает поведение системы в двух конфигурациях: автономный режим (Master-узел без slave-узлов) и распределённый режим (Master-узел с шестью slave-узлами).

 

Рисунок 3.1 – Зависимость среднего времени отклика от количества 
пользователей

Длительный тест стабильности, продолжавшийся 5 минут, подтвердил отсутствие утечек памяти и деградации производительности при непрерывной работе в обеих конфигурациях. За это время было успешно обработано более 450 запросов. Система ежесекундно проверяла свой статус через специальный эндпоинт, и все проверки завершались успешно, что свидетельствует о стабильной работе всех компонентов системы в течение продолжительного времени. Сводные результаты всех тестов позволяют заключить, что разработанная система демонстрирует высокую надёжность и эффективно масштабируется, начиная с уровня 30 одновременных пользователей, что подтверждает выполнение всех ключевых требований курсового проекта.

3.4	Апробация приложения

Экспериментальная апробация системы проводилась для проверки её работоспособности, удобства интерфейса и качества суммаризации. Тестирование включало функциональную проверку всех компонентов и оценку результатов на текстах различного объёма и тематики.
Пользовательский интерфейс реализован в виде одностраничного веб-приложения (рис. 3.2). Интерфейс содержит две основные кнопки: для выбора файла и отправки его на сервер. Минималистичный дизайн обеспечивает простоту использования – пользователь загружает файл и запускает обработку одним нажатием. Система автоматически определяет формат и извлекает текстовое содержимое, что исключает необходимость ручной конвертации.

 

Рисунок 3.2 – HTML страница пользователя

Во время обработки отображается индикатор выполнения, дающий обратную связь о текущем состоянии операции. Это особенно важно при работе с большими документами, когда время обработки может достигать десятков секунд. На рисунке 3.3 представлен процесс обработки.

 

Рисунок 3.3 – Обработка текста

Результаты суммаризации отображаются в отдельном блоке интерфейса (рис. 3.4). Помимо самого сокращённого текста, система показывает метрики обработки: исходный и итоговый объём (в символах и килобайтах), коэффициент сжатия и время выполнения. Такая детализация позволяет пользователю оценить эффективность работы системы.

 

Рисунок 3.4 – Результат суммаризации

Качество суммаризации проверялось на научных статьях, технической документации, новостях и литературных текстах. Система стабильно сохраняла смысловое ядро даже при значительном сокращении. Например, научная статья объёмом 15 000 символов была сокращена до 4 500 символов с сохранением ключевых гипотез, методики и выводов. Новостные материалы эффективно сводились к описанию основных событий и участников.
Количественные результаты подтвердили эффективность алгоритма TextRank. Текстовый файл объёмом 9,66 КБ был сокращён до 2,67 КБ (степень сжатия 72,4%). Документ объёмом 89,46 КБ уменьшился до 27,5 КБ (степень сжатия 69,2%). Степень сжатия является настраиваемым параметром в диапазоне от 10% до 90%. Оптимальным оказалось сокращение на 60–75%, поскольку более агрессивное сжатие ведёт к потере смысловых связей, а менее интенсивное не даёт существенного выигрыша.
Тестирование отказоустойчивости включало сценарии с отключением slave-узлов во время работы, сетевые сбои и обработку файлов с проблемной кодировкой. Система демонстрировала стабильное поведение: при потере узла задача перенаправлялась на другой доступный узел, при сетевых проблемах выполнялись повторные попытки передачи, а кодировка определялась автоматически. Время восстановления после сбоя не превышало 5 секунд.
Производительность проверялась при разном количестве slave-узлов. Как показано в разделе 3.4, для текстов от 50 000 символов система масштабируется практически линейно. Для малых текстов распределённая обработка менее эффективна из-за накладных расходов, но система автоматически выбирает оптимальную стратегию на основе объёма данных и текущей загрузки узлов.
Апробация подтвердила работоспособность всех компонентов системы, её практическую полезность для автоматической суммаризации текстов и соответствие требованиям по производительности, масштабируемости и удобству использования.
 
ЗАКЛЮЧЕНИЕ

В результате выполненной работы разработана распределённая система для автоматической суммаризации текстов на основе архитектуры Master-Slave. Система использует REST API для взаимодействия с клиентами и UDP-протокол для внутренней коммуникации между узлами. Реализация выполнена на языке C# с применением платформы .NET.
Проведённый аналитический обзор позволил обоснованно выбрать ключевые технологии: архитектуру Master-Slave для распределения нагрузки, алгоритм TextRank для экстрактивной суммаризации, а также оптимальное сочетание сетевых протоколов. Выбор C# в качестве языка разработки обеспечил высокую производительность и надёжность системы благодаря встроенной поддержке асинхронного программирования и развитым сетевым возможностям.
Важным достижением стала реализация механизма динамической балансировки нагрузки с выбором наименее загруженного узла. Система демонстрирует отказоустойчивость за счёт мониторинга состояния узлов и автоматического перераспределения задач при сбоях. Поддержка различных форматов входных файлов расширяет практическую применимость решения.
Экспериментальная проверка подтвердила работоспособность системы и её способность к масштабированию. Тестирование выявило закономерности производительности в зависимости от количества узлов и уровня нагрузки, что позволило сформулировать рекомендации по оптимальной конфигурации системы.
Разработанное решение имеет практическую ценность для обработки больших объёмов текстовой информации в различных областях. Система может интегрироваться в существующие инфраструктуры или использоваться как самостоятельный сервис.
Перспективными направлениями развития являются расширение поддерживаемых форматов, реализация пакетной обработки и дальнейшая оптимизация алгоритмов балансировки нагрузки.



